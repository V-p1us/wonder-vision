{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-worth",
   "metadata": {
    "id": "conservative-worth"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import shutil\n",
    "import pathlib\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blessed-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include submodule paths\n",
    "sys.path.insert(0, './detector/scaledyolov4/parent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "friendly-stroke",
   "metadata": {
    "id": "friendly-stroke"
   },
   "outputs": [],
   "source": [
    "from detector.scaledyolov4.parent.utils.general import non_max_suppression, scale_coords, xyxy2xywh, plot_one_box\n",
    "from detector.scaledyolov4.parent.utils.torch_utils import select_device, time_synchronized\n",
    "\n",
    "from detector.scaledyolov4.parent.models.models import Darknet, load_darknet_weights\n",
    "from detector.scaledyolov4.parent.utils.datasets import letterbox\n",
    "from detector.scaledyolov4.parent.detect import load_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "GNd9LKdjbdiN",
   "metadata": {
    "id": "GNd9LKdjbdiN"
   },
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9EqicJGcqdCr",
   "metadata": {
    "id": "9EqicJGcqdCr"
   },
   "outputs": [],
   "source": [
    "class VideoLoader:\n",
    "    # No support for parallel processing\n",
    "    \n",
    "    CODEC = cv2.CAP_FFMPEG\n",
    "\n",
    "    def __init__(self, path, post_process = lambda x: x):\n",
    "        self._path = path\n",
    "        self._video_buffer = cv2.VideoCapture(path, cv2.CAP_FFMPEG)\n",
    "        self._post_process = post_process\n",
    "    \n",
    "    def __len__(self):\n",
    "        n_frames = self._video_buffer.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        assert int(n_frames) == n_frames, 'Frame count has to be an integer'\n",
    "        return int(n_frames)\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self._video_buffer.isOpened():\n",
    "            self._video_buffer.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        else:\n",
    "            self._video_buffer = cv2.VideoCapture(self._path, self.CODEC)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        success, raw_frame = self._video_buffer.read()\n",
    "        if success:\n",
    "            return self._post_process(raw_frame), raw_frame\n",
    "        else:\n",
    "            self._video_buffer.release()\n",
    "            raise StopIteration\n",
    "\n",
    "    def get_param(self, key):\n",
    "        return self._video_buffer.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "SS-6wleujqTC",
   "metadata": {
    "id": "SS-6wleujqTC"
   },
   "outputs": [],
   "source": [
    "def process_frame(frame, img_size):\n",
    "    \"\"\"\n",
    "    Resizes images as per the model input size\n",
    "    Changes the channel order\n",
    "    \"\"\"\n",
    "    img, *_ = letterbox(frame, img_size)\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)    # BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prime-filling",
   "metadata": {
    "id": "prime-filling"
   },
   "outputs": [],
   "source": [
    "def load_model(img_size=640,\n",
    "               device='cpu',\n",
    "               half=False,\n",
    "               cfg='yolov4/models/yolov4-csp.cfg',\n",
    "               weights='yolov4/weights/yolov4-csp.weights'):\n",
    "    model = Darknet(cfg, img_size)\n",
    "    load_darknet_weights(model, weights)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model.half() if half else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "QHUnpj8X4ucy",
   "metadata": {
    "id": "QHUnpj8X4ucy"
   },
   "outputs": [],
   "source": [
    "args = AttrDict()\n",
    "args.video_path = pathlib.Path('data/ai_city/counting_gt_sample/counting_example_cam_5_1min.mp4')\n",
    "\n",
    "args.model_args = AttrDict()\n",
    "args.model_args.img_size = 640\n",
    "args.model_args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.model_args.half = False\n",
    "\n",
    "args.model_paths = AttrDict()\n",
    "args.model_paths.cfg = 'detector/scaledyolov4/parent/models/yolov4-csp.cfg'\n",
    "args.model_paths.weights = 'detector/scaledyolov4/weights/yolov4-csp.weights'\n",
    "    \n",
    "args.det_params = AttrDict()\n",
    "args.det_params.conf_thres = 0.4\n",
    "args.det_params.iou_thres = 0.5\n",
    "args.det_params.agnostic_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "xDI5na7oX_nS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDI5na7oX_nS",
    "outputId": "6912238d-8266-491f-f949-c6babf17454d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 342 layers, 5.29214e+07 parameters, 5.29214e+07 gradients\n"
     ]
    }
   ],
   "source": [
    "frame_loader = VideoLoader(str(args.video_path),\n",
    "                           post_process=functools.partial(process_frame,\n",
    "                                                          img_size=args.model_args.img_size))\n",
    "\n",
    "model = load_model(**args.model_args, **args.model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "qRVl8Lx55Z51",
   "metadata": {
    "id": "qRVl8Lx55Z51"
   },
   "outputs": [],
   "source": [
    " # cudnn.benchmark = True  # set True to speed up constant image size inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banner-blake",
   "metadata": {
    "id": "banner-blake"
   },
   "outputs": [],
   "source": [
    "def detect(model, frame, raw_frame, model_args, params):\n",
    "    frame = torch.tensor(frame, device=model_args.device,\n",
    "                         dtype=torch.float16 if model_args.half else torch.float32)\n",
    "    frame /= 255.0\n",
    "\n",
    "    if frame.dim() == 3:\n",
    "        frame.unsqueeze_(dim=0)\n",
    "\n",
    "    # Inference\n",
    "    pred = model(frame, augment=False)[0]\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred,\n",
    "                               params.conf_thres,\n",
    "                               params.iou_thres,\n",
    "                               classes=None,\n",
    "                               agnostic=params.agnostic_nms)\n",
    "    # Process detections and save results\n",
    "    for i, det in enumerate(pred):\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from processed frame coord to original frame coord\n",
    "            det[:, :4] = scale_coords(frame.shape[2:], det[:, :4], raw_frame.shape).round()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jLcbkjKmuu7D",
   "metadata": {
    "id": "jLcbkjKmuu7D"
   },
   "outputs": [],
   "source": [
    "save_txt = True\n",
    "save_vid = True\n",
    "view_vid = False\n",
    "out_folder = 'outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "xJXPRTjG5Lmj",
   "metadata": {
    "id": "xJXPRTjG5Lmj"
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "out_path = pathlib.Path(out_folder) / pathlib.Path(args.video_path).stem\n",
    "if os.path.exists(out_path):\n",
    "    shutil.rmtree(out_path)  # delete output folder\n",
    "os.makedirs(out_path)\n",
    "\n",
    "# Get names and colors\n",
    "names = 'detector/scaledyolov4/parent/data/coco.names'\n",
    "names = load_classes(names)\n",
    "colors = [[np.random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Cpy4L8mJYAqn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cpy4L8mJYAqn",
    "outputId": "3d00a741-c41b-46b9-f584-67443ac78cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to outputs/counting_example_cam_5_1min\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Process frames one-by-one sequentially\n",
    "    for i, (inp_frame, raw_frame) in enumerate(frame_loader):\n",
    "        t1 = time_synchronized()\n",
    "        detections = detect(model, inp_frame, raw_frame,\n",
    "                            model_args=args.model_args,\n",
    "                            params=args.det_params)[0]\n",
    "        t2 = time_synchronized()\n",
    "        \n",
    "        if ((save_txt or save_vid or view_vid) and \n",
    "            detections is not None and len(detections)):\n",
    "            gn = torch.tensor(raw_frame.shape)[[1, 0, 1, 0]]\n",
    "            for *xyxy, conf, cls in detections:\n",
    "                # write restults to file\n",
    "                if save_txt:\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    with open(out_path / 'results.txt', 'a') as f:\n",
    "                        f.write(('%g ' * 6 + '\\n') % (i, cls, *xywh))  # label format\n",
    "                # Add bounding box to image\n",
    "                if save_vid or view_vid:\n",
    "                        label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                        plot_one_box(xyxy, raw_frame, label=label,\n",
    "                                     color=colors[int(cls)], line_thickness=3)\n",
    "            # Stream results\n",
    "            if view_vid:\n",
    "                cv2.imshow(str(args.video_path), raw_frame)\n",
    "                if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "                    raise StopIteration\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_vid:\n",
    "                if i == 0:\n",
    "                    vid_path = out_path / pathlib.Path(args.video_path).name\n",
    "                    fourcc = 'mp4v'  # output video codec\n",
    "                    fps = frame_loader.get_param(cv2.CAP_PROP_FPS)\n",
    "                    w = int(frame_loader.get_param(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    h = int(frame_loader.get_param(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    vid_writer = cv2.VideoWriter(str(vid_path), cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n",
    "                vid_writer.write(raw_frame)\n",
    "    if save_txt or save_vid:\n",
    "        print('Results saved to %s' % out_path)\n",
    "    if save_vid:\n",
    "        vid_writer.release()\n",
    "    if view_vid:\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
